{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- User's settings -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of digested data\n",
    "input_directory = '/digested/'\n",
    "\n",
    "# Desired location to save trained model\n",
    "model_directory = '/model_directory/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- (semi)-Automatic -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy\n",
    "import pickle\n",
    "import os.path\n",
    "import tensorflow\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure CPU/GPU devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------- If using Tensorflow-GPU: -------- #\n",
    "\n",
    "configuration = tensorflow.ConfigProto()\n",
    "\n",
    "configuration.gpu_options.allow_growth = True\n",
    "\n",
    "configuration.gpu_options.visible_device_list = \"0\"\n",
    "\n",
    "session = tensorflow.Session(config=configuration)\n",
    "\n",
    "keras.backend.set_session(session)\n",
    "\n",
    "\n",
    "# -------- If using Tensorflow (CPU) : -------- #\n",
    "\n",
    "# configuration = tensorflow.ConfigProto()\n",
    "\n",
    "# session = tensorflow.Session(config=configuration)\n",
    "\n",
    "# keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data queueing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_data_generator(input_x, input_y, batch_size):\n",
    "    num_examples, num_labels = input_y.shape\n",
    "    label_indices = []\n",
    "    for i in range(num_labels):\n",
    "        indices = [j for j in range(num_examples) if input_y[j,i] > 0]\n",
    "        label_indices.append(indices)\n",
    "        print(\"Label\",i,\":\",len(indices),\"examples\")\n",
    "    samples_per_label = int(batch_size / num_labels)\n",
    "\n",
    "    def generator():\n",
    "        while True:\n",
    "            x_samples = []\n",
    "            y_samples = []\n",
    "            for i in range(num_labels):\n",
    "                random.shuffle(label_indices[i])\n",
    "                indices = label_indices[i][0:samples_per_label]\n",
    "                x_samples.append( input_x[indices, ...] )\n",
    "                y_samples.append( input_y[indices, ...] )\n",
    "            x_samples = numpy.concatenate( x_samples )\n",
    "            y_samples = numpy.concatenate( y_samples )\n",
    "            batch_indices = numpy.arange(x_samples.shape[0])\n",
    "            numpy.random.shuffle(batch_indices)\n",
    "            x_samples = x_samples[batch_indices, ...]\n",
    "            y_samples = y_samples[batch_indices, ...]\n",
    "            yield (x_samples, y_samples)\n",
    "    return generator()\n",
    "\n",
    "\n",
    "def prediction_data_generator(input_x, input_y, batch_size):\n",
    "    num_examples, num_labels = input_y.shape\n",
    "    steps = int(num_examples / batch_size)\n",
    "    def generator():\n",
    "        i = 0\n",
    "        while True:\n",
    "            start = i*batch_size\n",
    "            end = (i+1)*batch_size\n",
    "            x_sample = input_x[start:end, ...]\n",
    "            y_sample = input_y[start:end, ...]\n",
    "            yield (x_sample, y_sample)\n",
    "            i = i + 1 if i < steps else 0\n",
    "    print(\"Prediction steps:\",steps)        \n",
    "    return generator(), steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function to normalize illumination discrepancy across images\n",
    "\n",
    "def min_max_norm(x, minimum=None, maximum=None):\n",
    "    channels = x.shape[-1]\n",
    "    if minimum is None and maximum is None:\n",
    "        minimum = []\n",
    "        maximum = []\n",
    "        for channel in range(channels):\n",
    "            minimum.append( x[..., channel].min() )\n",
    "            maximum.append( x[..., channel].max() )\n",
    "    result = numpy.zeros_like(x)\n",
    "    for ch in range(channels):\n",
    "        result[..., ch] = 100.0*( (numpy.ndarray.astype(x[..., ch], numpy.float32) - minimum[ch])/(maximum[ch] - minimum[ch]) )\n",
    "    return (result, minimum, maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images are saved inside this tensor rank 4, \"Tensor\", shape: (33060, 48, 48, 1)\n",
      "All labels are encoded in this one-hot label tensor rank 2, \"Labels\" ,shape: (33060, 7)\n",
      "Training tensor \"training_x\" was saved, shape: (26444, 48, 48, 1)\n",
      "Validation tensor \"validation_x\" was saved, shape: (3306, 48, 48, 1)\n",
      "Testing tensor \"testing_x\" was saved, shape: (3310, 48, 48, 1)\n",
      "Number of objects in each class:\n",
      "0 Anaphase 128\n",
      "1 G1 14333\n",
      "2 G2 8601\n",
      "3 Metaphase 552\n",
      "4 Prophase 606\n",
      "5 S_phase 8616\n",
      "6 Telophase 224\n",
      "Class weight(s) :  {0: 258.28125, 1: 2.3065652689597433, 2: 3.843739100104639, 3: 59.891304347826086, 4: 54.554455445544555, 5: 3.8370473537604455, 6: 147.58928571428572}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ]
    }
   ],
   "source": [
    "# class_weights = pickle.load(open(os.path.join(input_directory, \"class_weights.sav\"), 'rb'))\n",
    "classes = len( pickle.load(open(os.path.join(input_directory, \"class_names.sav\"), 'rb')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_x = numpy.load(os.path.join(input_directory, \"training_x.npy\"))\n",
    "\n",
    "training_y = numpy.load(os.path.join(input_directory, \"training_y.npy\"))\n",
    "\n",
    "validation_x = numpy.load(os.path.join(input_directory, \"validation_x.npy\"))\n",
    "\n",
    "validation_y = numpy.load(os.path.join(input_directory, \"validation_y.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading training data\")\n",
    "\n",
    "# Use this function to normalize signal intensities across images\n",
    "training_x, pix_min, pix_max = min_max_norm(training_x)\n",
    "\n",
    "training_generator = training_data_generator(training_x, training_y, 32) \n",
    "\n",
    "print(training_x.shape, training_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading validation data\")\n",
    "\n",
    "# Use this function to normalize signal intensities across images\n",
    "validation_x, _, _ = min_max_norm(validation_x, pix_min, pix_max)\n",
    "\n",
    "validation_generator, validation_steps = prediction_data_generator(validation_x, validation_y, 32)\n",
    "\n",
    "print(validation_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct convolutional neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = (training_x.shape[1], training_x.shape[2], training_x.shape[3])\n",
    "\n",
    "x = keras.layers.Input(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options = {\"activation\": None, \"kernel_size\": (3, 3), \"padding\": \"same\"}\n",
    "\n",
    "# Block 1:\n",
    "\n",
    "y = keras.layers.Conv2D(32, **options)(x)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.Conv2D(32, **options)(y)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "# Block 2:\n",
    "y = keras.layers.Conv2D(64, **options)(y)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.Conv2D(64, **options)(y)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same')(y)\n",
    "\n",
    "# Block 3:\n",
    "y = keras.layers.Conv2D(128, **options)(y)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.Conv2D(128, **options)(y)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same')(y)\n",
    "\n",
    "# Block 3:\n",
    "y = keras.layers.Conv2D(256, **options)(y)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.Conv2D(256, **options)(y)\n",
    "y = keras.layers.Activation(\"relu\")(y)\n",
    "y = keras.layers.normalization.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same')(y)\n",
    "\n",
    "# Block 5:\n",
    "y = keras.layers.Flatten()(y)\n",
    "y = keras.layers.Dense(1024, activation=\"relu\")(y)\n",
    "y = keras.layers.Dropout(0.5)(y)\n",
    "y = keras.layers.Dense(classes)(y)\n",
    "y = keras.layers.Activation(\"softmax\")(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              9438208   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 7175      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 10,617,063.0\n",
      "Trainable params: 10,617,063.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-04-21 19:56:08.266801. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = keras.losses.categorical_crossentropy\n",
    "\n",
    "optimizer = keras.optimizers.Adam(0.00001)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss, \n",
    "    metrics=[\n",
    "        \"accuracy\"\n",
    "    ],\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# -------- If using Tensorflow (CPU) : -------- #\n",
    "\n",
    "# init = tensorflow.global_variables_initializer()\n",
    "\n",
    "# session.run(init)\n",
    "\n",
    "# -------------------------------------------- #\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    callbacks=[\n",
    "        keras.callbacks.CSVLogger( os.path.join(model_directory, 'training.csv') ),\n",
    "        keras.callbacks.ModelCheckpoint( os.path.join(model_directory, 'checkpoint.hdf5') )\n",
    "    ],\n",
    "    epochs=18,\n",
    "    generator = training_generator,\n",
    "    verbose = 0, # ON/OFF printing output\n",
    "    max_q_size = 256,\n",
    "    steps_per_epoch=2500,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 2500\n",
    ")\n",
    "\n",
    "stop = time.time()\n",
    "print(stop - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save( os.path.join(model_directory, 'model.h5') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
