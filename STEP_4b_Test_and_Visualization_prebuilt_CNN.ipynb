{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- User's settings -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of digested data\n",
    "input_directory = '/digested/'\n",
    "\n",
    "# Desired location to save temporary PNG outputs:\n",
    "png_directory = '/digested_png/'\n",
    "\n",
    "# Location of saved trained model\n",
    "model_directory = '/model_directory/'\n",
    "\n",
    "# Desired location for outputs\n",
    "output_directory = '/output_directory_transferred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define native shape of the transferred model (refer to model documentation)\n",
    "shape=(197,197,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- (semi)-Automatic -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import pickle\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "import numpy\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import seaborn\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure GPU/CPU devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------- If using Tensorflow-GPU: -------- #\n",
    "\n",
    "configuration = tensorflow.ConfigProto()\n",
    "\n",
    "configuration.gpu_options.allow_growth = True\n",
    "\n",
    "configuration.gpu_options.visible_device_list = \"0\"\n",
    "\n",
    "session = tensorflow.Session(config=configuration)\n",
    "\n",
    "keras.backend.set_session(session)\n",
    "\n",
    "\n",
    "# -------- If using Tensorflow (CPU) : -------- #\n",
    "\n",
    "# configuration = tensorflow.ConfigProto()\n",
    "\n",
    "# session = tensorflow.Session(config=configuration)\n",
    "\n",
    "# keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_x = numpy.load(os.path.join(input_directory, \"testing_x.npy\"))\n",
    "\n",
    "testing_y = numpy.load(os.path.join(input_directory, \"testing_y.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack single-channel images (maximum 3 channels) and store to PNG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "digest.save_png(testing_x, os.path.join(png_directory,\"Testing\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "testing_generator = testing_generator.flow_from_directory(\n",
    "    batch_size=32,\n",
    "    color_mode=\"rgb\",\n",
    "    directory= os.path.join(png_directory,\"Testing\"),\n",
    "    target_size=(shape[0], shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model:\n",
    "(can also load checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model( os.path.join(model_directory, 'model.h5') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(model_directory, 'model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(\n",
    "    generator=testing_generator, \n",
    "    steps=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the most crucial layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for the densely/fully connected layer nearest to the classier, which is the one that has the shape of (None, number-of-classes)\n",
    "\n",
    "==================================================================\n",
    "\n",
    "Example 1: in case of classification of 7 classes, the last few layers are:\n",
    "\n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 1024)              943820   \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 1024)              0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 7)                 7175      \n",
    "_________________________________________________________________\n",
    "activation_1 (Activation)    (None, 7)                 0         \n",
    "\n",
    "\n",
    "then look for the layer dense_1 , which has a shape of (None, 1024) \n",
    "\n",
    "==================================================================\n",
    "\n",
    "Example 2: in case of classification of 5 classes, the last few layers are:\n",
    "\n",
    "activation_49 (Activation)       (None, 8, 8, 2048)    0                                            \n",
    "_________________________________________________________________\n",
    "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0                                            \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d_1 (Glob (None, 2048)          0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)                  (None, 5)             10245    \n",
    "\n",
    "then look for the layer global_average_pooling2d_1 , which has a shape of (None, 2048) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layers[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract_model = None # Clear cached abstract_model\n",
    "abstract_model = Sequential([layers[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_features = abstract_model.predict_generator(\n",
    "    generator=testing_generator,\n",
    "    steps=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Converting numeric labels into class names...')\n",
    "\n",
    "class_names = pickle.load(open(os.path.join(input_directory, \"class_names.sav\"), 'rb'))\n",
    "\n",
    "def save_metadata(file):\n",
    "    with open(file, 'w') as f:\n",
    "        for i in range(test_y.shape[0]):\n",
    "            f.write('{}\\n'.format( class_names[test_y[i]] ))     \n",
    "\n",
    "save_metadata( os.path.join(output_directory, 'metadata.tsv') )  \n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted values in .TXT\n",
    "To be uploaded and viewed on http://projector.tensorflow.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.savetxt( os.path.join(output_directory, 'table_of_features.txt' ), extracted_features, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "Once finished, open http://projector.tensorflow.org on web-browser.\n",
    "\n",
    "Click \"Load data\" on the left panel.\n",
    "\n",
    "- Step 1: Load a TSV file of vectors >> Choose file: 'table_of_features.txt'\n",
    "\n",
    "- Step 2: Load a TSV file of metadata >> Choose file: 'metadata.tsv'\n",
    "\n",
    "Hit ESC or click outside the load data window to dismiss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted values in .NPY\n",
    "Used for generating Tensorboard embeddings to be viewed locally on http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.save( os.path.join(output_directory, 'table_of_features.npy' ), extracted_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_features = numpy.load( 'table_of_features.npy' )\n",
    "embedding_var = tensorflow.Variable(extracted_features)\n",
    "\n",
    "embedSess = tensorflow.Session()\n",
    "\n",
    "# save variable in session\n",
    "embedSess.run(embedding_var.initializer)\n",
    "\n",
    "# save session (only used variable) to file\n",
    "saver = tensorflow.train.Saver([embedding_var])\n",
    "saver.save(embedSess, 'tf.ckpt')\n",
    "\n",
    "summary_writer = tensorflow.summary.FileWriter('./')\n",
    "\n",
    "config = tensorflow.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "embedding.metadata_path = 'metadata.tsv' # this metadata_path need to be modified later. See note.\n",
    "tensorflow.contrib.tensorboard.plugins.projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "embedSess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "Tensorboard embeddings files will be saved in the same location with this script.\n",
    "\n",
    "Collect the following files into one folder:\n",
    "\n",
    "- metadata.tsv\n",
    "- checkpoint\n",
    "- projector_config.pbtxt\n",
    "- tf.ckpt.index\n",
    "- tf.ckpt.meta\n",
    "- tf.ckpt.data-00000-of-00001\n",
    "\n",
    "Open with any text editor : \"projector_config.pbtxt\"\n",
    "\n",
    "\"/path/to/logdir/metadata.tsv\" has to be specified, CANNOT be relative path \"./metadata.tsv\", nor \"~/metadata.tsv\"\n",
    "\n",
    "Then type command in terminal: tensorboard --logdir=\"/path/to/logdir\"\n",
    "\n",
    "Next, open web-browser, connect to http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot categorical accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = pandas.read_csv(os.path.join(model_directory, 'training.csv') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.pyplot.plot(metrics[\"acc\"])\n",
    "matplotlib.pyplot.plot(metrics[\"val_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.pyplot.plot(metrics[\"loss\"])\n",
    "matplotlib.pyplot.plot(metrics[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(\n",
    "    batch_size=50,\n",
    "    x=testing_x\n",
    ")\n",
    "\n",
    "predicted = numpy.argmax(predicted, -1)\n",
    "expected = numpy.argmax(testing_y[:, :], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "confusion = pandas.DataFrame(confusion)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(12, 8))\n",
    "\n",
    "seaborn.heatmap(confusion, annot=True)\n",
    "\n",
    "matplotlib.pyplot.savefig( os.path.join(output_directory, 'confusion_matrix.eps') , format='eps', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
